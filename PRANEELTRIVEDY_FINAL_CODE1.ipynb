{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eeb4f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3619d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         instance_id                                         sentence_1  \\\n",
      "0        train_id_0  Is it in the food supply ? \" says David Ropeik...   \n",
      "1        train_id_1  Hundreds of soldiers were involved , an appare...   \n",
      "2        train_id_2  And Sen. Michael Crapo , R-Idaho , chairman of...   \n",
      "3        train_id_3  The gunman , 26-year-old Harold Kilpatrick jnr...   \n",
      "4        train_id_4  The League of United Latin American Citizens ,...   \n",
      "...             ...                                                ...   \n",
      "7796  train_id_7796  Toll last week offered to buy the company for ...   \n",
      "7797  train_id_7797  Experts say they think better treatment , incl...   \n",
      "7798  train_id_7798  The Dow Jones industrial average < .DJI > rose...   \n",
      "7799  train_id_7799  In Sweden , 99 percent of women are literate ,...   \n",
      "7800  train_id_7800  Tornadoes , up to a foot of rain and hail as b...   \n",
      "\n",
      "                                             sentence_2  gold_label  \n",
      "0     The pound also made progress against the dolla...           0  \n",
      "1     Avants , wearing a light brown jumpsuit , had ...           0  \n",
      "2     . 's Kempthorne of friend longtime a is , nomi...           0  \n",
      "3     \" In fact , I was physically sick several time...           0  \n",
      "4     No. 2 HP saw its Unix server sales dropped 3.6...           0  \n",
      "...                                                 ...         ...  \n",
      "7796  Toll , Australia 's second-largest transport c...           1  \n",
      "7797  Experts say they think better treatment , incl...           0  \n",
      "7798  . 8,949.00 to , percent 1.12 or , points 98.74...           0  \n",
      "7799  In Sweden , 99 percent of women are literate w...           1  \n",
      "7800  . homes four least at destroying and man one k...           0  \n",
      "\n",
      "[7801 rows x 4 columns]>\n",
      "(7801, 4)\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "7796    1\n",
      "7797    0\n",
      "7798    0\n",
      "7799    1\n",
      "7800    0\n",
      "Name: gold_label, Length: 7801, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train_with_label.csv\")\n",
    "df_train.head()\n",
    "print(df_train.head)\n",
    "print(df_train.shape)\n",
    "train_labels = df_train['gold_label']\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c14d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                          sentence_number\n",
      "0      He said he did not think that the Shenzhou V l...\n",
      "1      Under NASD regulations , Mr. Young can file a ...\n",
      "2      In Europe , France 's CAC-40 rose 0.6 percent ...\n",
      "3      Schroeder cancelled his Italian holiday after ...\n",
      "4      U.S. District Judge William Barbour said he im...\n",
      "...                                                  ...\n",
      "31597  \" As a professional , \" he added , \" I think I...\n",
      "31598  Shares of Mandalay closed down 8 cents at $ 29...\n",
      "31599  Local police authorities are treating the expl...\n",
      "31600  There are 625 U.N. troops in Bunia , while the...\n",
      "31601  . directions both in kbps 200 exceeding speeds...\n",
      "\n",
      "[31602 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "universe = pd.read_csv(\"vocabulary.csv\")\n",
    "print(universe.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3a9380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def clean_text(txt):\n",
    "    text = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    tokens = re.split('\\W+', txt)\n",
    "    txt = \" \".join([ps.stem(word) for word in tokens if word not in stopwords])\n",
    "    txt = txt.lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b0063852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                          sentence_number  \\\n",
      "0      He said he did not think that the Shenzhou V l...   \n",
      "1      Under NASD regulations , Mr. Young can file a ...   \n",
      "2      In Europe , France 's CAC-40 rose 0.6 percent ...   \n",
      "3      Schroeder cancelled his Italian holiday after ...   \n",
      "4      U.S. District Judge William Barbour said he im...   \n",
      "...                                                  ...   \n",
      "31597  \" As a professional , \" he added , \" I think I...   \n",
      "31598  Shares of Mandalay closed down 8 cents at $ 29...   \n",
      "31599  Local police authorities are treating the expl...   \n",
      "31600  There are 625 U.N. troops in Bunia , while the...   \n",
      "31601  . directions both in kbps 200 exceeding speeds...   \n",
      "\n",
      "                                             vocab_clean  \n",
      "0      he said think shenzhou v launch militari appli...  \n",
      "1      under nasd regul mr young file respons request...  \n",
      "2      in europ franc cac 40 rose 0 6 percent britain...  \n",
      "3      schroeder cancel italian holiday stefani refus...  \n",
      "4      u s district judg william barbour said impos m...  \n",
      "...                                                  ...  \n",
      "31597   as profession ad i think i like thought good ...  \n",
      "31598        share mandalay close 8 cent 29 42 thursday   \n",
      "31599  local polic author treat explos crimin matter ...  \n",
      "31600  there 625 u n troop bunia 25 000 28 000 tribal...  \n",
      "31601   direct kbp 200 exceed speed servic servic adv...  \n",
      "\n",
      "[31602 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_train['sent1_clean'] = df_train['sentence_1'].apply(lambda x: clean_text(x))\n",
    "df_train['sent2_clean'] = df_train['sentence_2'].apply(lambda x: clean_text(x))\n",
    "universe['vocab_clean'] = universe['sentence_number'].apply(lambda x: clean_text(x))\n",
    "print(universe.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1adf2ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11354"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer().fit(universe['vocab_clean']) #learn all tokens in raw document\n",
    "tokens = cv.get_feature_names()\n",
    "len(tokens) #this is a list of all unique words\n",
    "\n",
    "\n",
    "#all the words in all sentences from train, dev, test\n",
    "#dictionary.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3fead21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7801, 11354)\n",
      "(7801, 11354)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(vocabulary = tokens)\n",
    "X = vectorizer.fit_transform(df_train['sent1_clean'])\n",
    "traindf1_sent1 = pd.DataFrame(X.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())\n",
    "print(traindf1_sent1.shape)\n",
    "\n",
    "Y = vectorizer.fit_transform(df_train['sent2_clean'])\n",
    "traindf1_sent2 = pd.DataFrame(X.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())\n",
    "print(traindf1_sent2.shape)\n",
    "\n",
    "#acheived two sparse dfs with same size of universe of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ab9de0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as geek\n",
    "\n",
    "X1 = traindf1_sent1.to_numpy()\n",
    "X2 = traindf1_sent2.to_numpy()\n",
    "\n",
    "train_final = geek.add(X1, X2)\n",
    "print(train_final.max())\n",
    "\n",
    "#add data frames together to get overlapping words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf691ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9aaaba76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(100, 50, 3), max_iter=500,\n",
       "              random_state=1)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,50,3), max_iter = 500, activation = 'relu', solver = 'adam', alpha = 0.001, random_state = 1)\n",
    "mlp.fit(train_final,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d53800ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       instance_id                                         sentence_1  \\\n",
      "0        dev_id_0  He said he did not think that the Shenzhou V l...   \n",
      "1        dev_id_1  Under NASD regulations , Mr. Young can file a ...   \n",
      "2        dev_id_2  In Europe , France 's CAC-40 rose 0.6 percent ...   \n",
      "3        dev_id_3  Schroeder cancelled his Italian holiday after ...   \n",
      "4        dev_id_4  U.S. District Judge William Barbour said he im...   \n",
      "...           ...                                                ...   \n",
      "3995  dev_id_3995  Authorities said the bodies of a man and woman...   \n",
      "3996  dev_id_3996  The most common side effects after getting the...   \n",
      "3997  dev_id_3997  Russian cosmonaut Malenchenko achieved a first...   \n",
      "3998  dev_id_3998  Maddox , who had battled cancer since 1983 , c...   \n",
      "3999  dev_id_3999  She appeared in federal court there Monday and...   \n",
      "\n",
      "                                             sentence_2  gold_label  \n",
      "0     He said he did not think that the Shenzhou V l...           0  \n",
      "1     Josephine Burke , who ran the unlicensed dayca...           0  \n",
      "2     IBM shares closed up $ 1.75 , or 2.11 percent ...           0  \n",
      "3     Schroeder cancelled his Italian holiday after ...           0  \n",
      "4     Federal Judge William Barbour said Tuesday he ...           1  \n",
      "...                                                 ...         ...  \n",
      "3995  When asked where the weapons were , Rice said ...           0  \n",
      "3996  Common side effects include nasal congestion ,...           1  \n",
      "3997  It even struck a deal for distribution and adv...           0  \n",
      "3998  Maddox , 87 , cracked two ribs when he fell ab...           1  \n",
      "3999  \" It 's obvious I 'm not riding as well as yea...           0  \n",
      "\n",
      "[4000 rows x 4 columns]>\n",
      "(4000, 4)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "#move into validation set\n",
    "\n",
    "df_dev = pd.read_csv(\"dev_with_label.csv\")\n",
    "print(df_dev.head)\n",
    "print(df_dev.shape)\n",
    "dev_labels = df_dev['gold_label']\n",
    "print(dev_labels.shape)\n",
    "\n",
    "#loaded dev data and defined labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "723c6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean sentences\n",
    "\n",
    "df_dev['sent1_clean'] = df_dev['sentence_1'].apply(lambda x: clean_text(x))\n",
    "df_dev['sent2_clean'] = df_dev['sentence_2'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bec5bac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 11354)\n",
      "(4000, 11354)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_dev = CountVectorizer(vocabulary = tokens)\n",
    "dev1 = vectorizer_dev.fit_transform(df_dev['sent1_clean'])\n",
    "devdf1_sent1 = pd.DataFrame(dev1.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())\n",
    "print(devdf1_sent1.shape)\n",
    "\n",
    "dev2 = vectorizer_dev.fit_transform(df_dev['sent2_clean'])\n",
    "devdf1_sent2 = pd.DataFrame(dev2.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())\n",
    "print(devdf1_sent2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8654418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as geek\n",
    "\n",
    "D1 = devdf1_sent1.to_numpy()\n",
    "D2 = devdf1_sent2.to_numpy()\n",
    "\n",
    "dev_df_final = geek.add(D1, D2)\n",
    "print(dev_df_final.max())\n",
    "\n",
    "#add data frames together to get overlapping words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "baa629b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "prediction = mlp.predict(dev_df_final)\n",
    "print(prediction.shape)\n",
    "print(dev_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d597ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      3000\n",
      "           1       0.35      0.15      0.21      1000\n",
      "\n",
      "    accuracy                           0.72      4000\n",
      "   macro avg       0.56      0.53      0.52      4000\n",
      "weighted avg       0.66      0.72      0.67      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(dev_labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "74d1beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        instance_id                                         sentence_1  \\\n",
      "0        test_id_0  Jews , Americans and their allies had \" evil \"...   \n",
      "1        test_id_1  Zuccarini was ordered held without bail Wednes...   \n",
      "2        test_id_2  Contribute 2 costs 69 for an individual licens...   \n",
      "3        test_id_3  The gunman , 26-year-old Harold Kilpatrick jnr...   \n",
      "4        test_id_4  \" The bank requires growth from elsewhere in t...   \n",
      "...            ...                                                ...   \n",
      "3995  test_id_3995  \" As a professional , \" he added , \" I think I...   \n",
      "3996  test_id_3996  Carter , who received the Nobel Peace Prize la...   \n",
      "3997  test_id_3997  Thompson ordered Moore to remove the monument ...   \n",
      "3998  test_id_3998  Chief Justice William H. Rehnquist and Justice...   \n",
      "3999  test_id_3999  A total of 16.3 million lines provided advance...   \n",
      "\n",
      "                                             sentence_2  \n",
      "0     . said Amrozi , Indonesia like nations colonis...  \n",
      "1     . Fla , Lauderdale Fort in judge federal a by ...  \n",
      "2     The US version will cost $ 99 for an individua...  \n",
      "3     The gunman , identified as Harold Kilpatrick J...  \n",
      "4     In \" Open Range , \" Costner plays a cowboy who...  \n",
      "...                                                 ...  \n",
      "3995  \" As a professional , \" he added , \" I think I...  \n",
      "3996  Shares of Mandalay closed down 8 cents at $ 29...  \n",
      "3997  Local police authorities are treating the expl...  \n",
      "3998  There are 625 U.N. troops in Bunia , while the...  \n",
      "3999  . directions both in kbps 200 exceeding speeds...  \n",
      "\n",
      "[4000 rows x 3 columns]>\n",
      "(4000, 3)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test_without_label.csv\")\n",
    "print(df_test.head)\n",
    "print(df_test.shape)\n",
    "\n",
    "#loaded test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d2c489ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean sentences\n",
    "\n",
    "df_test['sent1_clean'] = df_test['sentence_1'].apply(lambda x: clean_text(x))\n",
    "df_test['sent2_clean'] = df_test['sentence_2'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f445f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 11354)\n",
      "(4000, 11354)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_test = CountVectorizer(vocabulary = tokens)\n",
    "test1 = vectorizer_test.fit_transform(df_test['sent1_clean'])\n",
    "test_sent1 = pd.DataFrame(test1.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())\n",
    "print(test_sent1.shape)\n",
    "\n",
    "test2 = vectorizer_test.fit_transform(df_test['sent2_clean'])\n",
    "test_sent2 = pd.DataFrame(test2.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())\n",
    "print(test_sent2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b739a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as geek\n",
    "\n",
    "T1 = test_sent1.to_numpy()\n",
    "T2 = test_sent2.to_numpy()\n",
    "\n",
    "test_df_final = geek.add(T1, T2)\n",
    "print(test_df_final.max())\n",
    "\n",
    "#add data frames together to get overlapping words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4f23a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = mlp.predict(test_df_final)\n",
    "print(test_prediction)\n",
    "\n",
    "newdf = pd.DataFrame(test_prediction)\n",
    "newdf.to_csv('test_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22d4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
